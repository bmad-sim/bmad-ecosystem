#!/usr/bin/python
#-*-python-*-
# 2.7.5
#
# The default packages build to use when constructing a new
# release build is determined by a symlink in the archive
# area for each platform.
#
# If a --pkg <package name> option is specified on the
# command line, then that packages build will be used
# when constructing the release build.
#------------------------------------------------------------------
import os
import sys
import time
import socket
import argparse
import ConfigParser
import subprocess as sub
import logging
import threading
import datetime

# Get 'repositories' and 'source_trees' dictionaries.
import build_config

# Get kerberos key for remote execution
hostname = socket.gethostname()
#p = sub.Popen('kinit -k -t ~/etc/cesrulib-keytab cesrulib',
p = sub.Popen('kinit -k -t /home/$USER/etc/$USER-keytab $USER',
              bufsize=1,
              shell=True,
              stdout=sub.PIPE )

# Print status of the script files with respect to the svn repository.
utildir = os.path.abspath(os.path.dirname(sys.argv[0]))
print 'SVN Status for util directory:'
os.system('svn st -u ' + utildir)

print '\nSVN Status for build_system directory:'
os.system('svn st -u ' + utildir + '/../build_system')
    
while True:
    nextline = p.stdout.readline()
    if nextline == '' and p.poll() != None:
        break
    sys.stdout.write(nextline)
    sys.stdout.flush()

# Logger
output_verbosity = logging.WARNING
logger = logging.getLogger('builder')
logger.setLevel(output_verbosity)
# Logger Console handler
loghandler = logging.StreamHandler()
loghandler.setLevel(output_verbosity)
# Logger formatter
formatter = logging.Formatter('%(name)s - %(message)s')
# Logger add formatter to handler
logger.addHandler( loghandler )


# Collect all supported platform names
all_platforms = []
for spec in build_config.build_specs:
    all_platforms.append( build_config.build_specs[spec]['platform'] )
# Remove any duplicate platforms from list
all_platforms = list(set(all_platforms))
#print 'Platforms that appear in collection of build specifications:'
#print all_platforms


argparser = argparse.ArgumentParser(description='Acelerator Libraries Collection Build Tool')

argparser.add_argument('--pkgname',
                       action='store',
                       dest='pkg_name')
argparser.add_argument('--gmakedir',
                       action='store',
                       dest='gmake_dir')
argparser.add_argument('--utildir',
                       action='store',
                       dest='util_dir')
argparser.add_argument('--spec',
                       action='store',
                       dest='build_spec',
                       help='Build specification')
argparser.add_argument('--nightly',
                       action='store_true',
                       dest='nightly')
argparser.add_argument('--online',
                       action='store_true',
                       dest='build_online_release',
                       help='Build the collection of libraries and programs for CESR online use.')
argparser.add_argument('--local',
                       action='store_true',
                       dest='local',
                       help='Build using local paths and resources.')
argparser.add_argument('--packages',
                       action='store_true',
                       dest='packages',
                       help='Build the collection of external Packages used for CESR online.')
muxgroup = argparser.add_mutually_exclusive_group()
muxgroup.add_argument('--intel',
                       action='store_true',
                       dest='intel',
                       help='Build using the Intel ifort compiler.')
muxgroup.add_argument('--gfortran',
                       action='store_true',
                       dest='gfortran',
                       help='Build using the GCC gfortran compiler.')


argresults = argparser.parse_args()

build_online_release = argresults.build_online_release

local = argresults.local

build_packages = argresults.packages

compiler_intel = argresults.intel

compiler_gfortran = argresults.gfortran

ACC_SET_GMAKE_JOBS = '2'

ACC_ENABLE_FPIC = 'N'

ACC_FC = 'intel'

ACC_SET_F_COMPILER = 'ifort'

build_request = 'release_intel'


# Defaults from config file.
makefile_dir_default = build_config.makefile_dir
if build_online_release:
    util_dir_default = build_config.online_util_dir
elif local:
    util_dir_default = build_config.local_util_dir
else:
    util_dir_default = build_config.offline_util_dir


if compiler_intel:
    ACC_FC = 'intel'
    ACC_SET_F_COMPILER = 'ifort'
    build_request = 'release_intel'

    if build_online_release:
        build_request = 'online-release_intel'

    if build_packages:
        build_request = 'packages_intel'

    if local:
        build_request = 'local-release_intel'

    if local and build_packages:
        build_request = 'local-packages_intel'

    #if build_dist:
        #build_request = 'dist_intel'


if compiler_gfortran:
    ACC_FC = 'gfortran'
    ACC_SET_F_COMPILER = 'gfortran'
    build_request = 'release_gfortran'

    if build_online_release:
        build_request = 'online-release_gfortran'

    if build_packages:
        build_request = 'packages_gfortran'

    if local:
        build_request = 'local-release_gfortran'

    if local and build_packages:
        build_request = 'local-packages_gfortran'

    #if build_dist:
        #build_request = 'dist_gfortran'


class BuildController(threading.Thread):

    # Defaults
    type = ''
    spec = ''
    platform = ''
    name = ''
    full_release_dir = ''

    svn_revision = 'HEAD'
    packages_name = 'packages'
    test_suite_run = 'False'
    util_dir = util_dir_default
    makefile_dir = makefile_dir_default

    if local:
        release_prefix = 'cesr-local'
    else:
        release_prefix = 'cesr'

    prefixes = {
        'release'  : release_prefix,
        'packages' : 'packages',
        'dist'     : 'CLASSE_accel_dist'
        }
    # Default numerical precision is 'double': IEEE 754-2008 (8 bytes)
    precision = 'double' 


    def __init__( self, spec, custom_name ):
        """Initialize the build_controller object."""
        threading.Thread.__init__(self)

        self.spec = spec
        self.type = build_config.build_specs[spec]['type']
        self.platform = build_config.build_specs[spec]['platform']
        self.basedir = build_config.build_specs[spec]['basedir']
        self.util_dir = build_config.build_specs[spec]['util_dir']
        self.email_list = build_config.build_specs[spec]['email_list']
        self.nightly = argresults.nightly
        self.local = argresults.local
        self.intel = argresults.intel
        self.gfortran = argresults.gfortran
        
        if not self.is_platform_supported():
            print 'Quitting.'
            sys.exit(1)
        if custom_name != '':
            self.name = custom_name
            self.uniqify_build_name()
        else:
            self.generate_build_name()
        self.full_release_dir = self.basedir + '/' + platform + '/' + self.name
        self.log_dir = self.basedir + '/' + platform + '/log'
        if not os.path.exists( self.log_dir ):
            print 'Log directory  ' + self.log_dir + '  does not exist!  Quitting.'
            sys.exit(1)
        self.full_logname = self.log_dir + '/' + self.name + '.log'
        self.hostname = build_config.build_specs[spec]['host']
        self.checkout_manifest = []

    
    def does_buildname_exist(self):
        """Determine if the currently assigned name of this build
        exists anywhere in the collection of supported platform
        directories.
        
        Scan through all defined platforms and check for the
        presence of a build directory that matches the name
        provided or generated.
        If the name checked exists in ANY platform base
        directories, modify the name with a counter and
        check again.
        Keep incrementing the counter and checking until
        the name does not exist in any platform base
        directory."""                
        already_exists = False
        for platform in all_platforms:
            checkdir = self.basedir + '/' + platform
            checkname = checkdir + '/' + self.name
            message = 'Checking for slot in ' + checkname + '... '
            if os.path.exists( checkname ):
                already_exists = True
                message = message + 'ALREADY EXISTS'
                logger.debug(message)
            else:
                message = message + 'OK'
                logger.debug(message)
        return already_exists


    def generate_build_name(self):
        """Generate a new build name from scratch based on
           the build type requested and the date.  This will
           provide a name unique across all supported platform
           directories."""
        timetuple  = time.localtime()
        year       = str(timetuple[0])
        if timetuple[1] < 10:                     # Clean this up with leading zeroes
            month      = '0' + str(timetuple[1])  # in original date retrieval?
        else:
            month      = str(timetuple[1])
        if timetuple[2] < 10:
            day        = '0' + str(timetuple[2])
        else:
            day        = str(timetuple[2])
        datecode   = year + '_' + month + day
        self.name = self.prefixes[self.type] + '_' + datecode + '_d'
        self.uniqify_build_name()


    def uniqify_build_name(self):
        """Make the build name unique by appending a counter
           to make it such if the build name at the time of
           invocation of this method already exists anywhere
           in the collection of supported platform directories."""
        count = 1
        orig_name = self.name
        while self.does_buildname_exist():
            self.name = orig_name + '_' + str(count)
            count = count + 1


    def is_platform_supported(self):
        if self.platform in all_platforms:
            if os.path.exists( self.basedir + '/' + self.platform ):
                return True
            else:
                print 'The build specification references the ' + self.platform + \
                      ' platform, but a corresponding directory does not exist in ' \
                      + self.basedir + '.'
                print 'Try creating it and run this again.'
                return False
        print 'Platform "' + self.platform + '" not mentioned in builder platform specifications.'
        return False


    def write_log_stub(self):
        """Write some identifying header fields in the platform-specific log file.
           Part of minimal set of methods needed to spawn a build."""
        print 'Opening ' + self.full_logname
        self.log = open(self.full_logname, 'w')
        self.log.write('build_host        ' + self.hostname +'\n')
        self.log.write('build_type        ' + self.type +'\n')
        self.log.write('libs_basedir      ' + self.basedir +'\n')
        self.log.write('platform          ' + self.platform +'\n')
        self.log.write('svn_revision      ' + str(self.svn_revision) +'\n')
        self.log.write('util_dir          ' + self.util_dir +'\n')
        self.log.write('makefile_dir      ' + self.makefile_dir +'\n')
        self.log.write('email_list        ' + self.email_list +'\n')
        self.log.write('build_name        ' + self.name  +'\n')
        self.log.write('full_release_dir  ' + self.full_release_dir +'\n')
        self.log.write('packages_name     ' + self.packages_name +'\n')
        self.log.write('nightly           ' + str(self.nightly) +'\n')
        self.log.write('local             ' + str(self.local) +'\n')
        self.log.write('intel             ' + str(self.intel) +'\n')
        self.log.write('gfortran          ' + str(self.gfortran) +'\n')
        self.write_checkout_manifest()
        self.log.write('[builder] - STARTING SUBSCRIPT\n')
        self.log.flush()


    def write_checkout_manifest(self):
        for reponame in build_config.build_specs[self.spec]['repositories']:
            self.log.write('repository  ' + build_config.repository_addresses[reponame] + '  ')
            for dir in build_config.build_specs[self.spec]['repositories'][reponame]:
                self.log.write(dir + '   ')
                self.checkout_manifest.append( dir )
        self.log.write('\n')
        self.log.flush()


    def checkout_files(self):
        """Check out all files described in the manifest
           associated with this build from the SVN repositories specified in
           the configuration file.  Get all files from the head revision at the time of 
           Part of minimal set of methods needed to spawn a build."""
        os.mkdir(self.full_release_dir)
        os.chdir(self.full_release_dir)
        for reponame in build_config.build_specs[self.spec]['repositories']:
            revision = svn_revisions[reponame]
            for dir in build_config.build_specs[self.spec]['repositories'][reponame]:
                #RT 60649
                if 'git/' == dir[:4]:
                    repo_address = build_config.repository_addresses['GitLab']
                    localdir = dir[4:]
                    checkout_command = 'git clone --quiet ' + repo_address + \
                                   localdir + '.git ' + self.full_release_dir + '/' + localdir
                    print ('CO: ' + checkout_command)
                else:
                    repo_address = build_config.repository_addresses[reponame]
                    localdir = os.path.split(dir)[1]
                    # Added klist commands to timestamp SVN access, as per RT#65510
                    checkout_command = 'klist -A ; svn -r ' + str(revision) + ' co ' + repo_address + \
                                   dir + ' ' + self.full_release_dir + '/' + localdir + ' ; klist -A '

                self.log.write('Checkout command: [' + checkout_command + ']\n')
                
                proc = sub.Popen(checkout_command,
                                 shell=True,
                                 stdin=sub.PIPE,
                                 stdout=sub.PIPE,
                                 stderr=sub.STDOUT )
                lines = proc.stdout.readlines()
                for line in lines:
                    self.log.write(line)


    def get_packages_name(self):
        """Obtain the default packages name to use for the build."""
        pass
        

    def set_test_suite_run(self, request):
        self.test_suite_run = request


    def run(self):
        """Execute the build process."""
        self.write_log_stub()
        self.checkout_files()
        build_command = ("ssh " + self.hostname + \
                        " 'export ACC_SET_GMAKE_JOBS=" + ACC_SET_GMAKE_JOBS + \
                        " ; export ACC_SET_F_COMPILER=" + ACC_SET_F_COMPILER + \
                        " ; export ACC_ENABLE_FPIC=" + ACC_ENABLE_FPIC + \
                        " ; [ -e /opt/rh/python27/enable ] && . /opt/rh/python27/enable" \
                        " ; python " + self.util_dir + "/builder " + self.full_logname + "'")
        print build_command
        p = sub.Popen(build_command, bufsize=-1, shell=True)
        p_out = p.communicate()[0]





#-----------------------
# Non-class code begins
#-----------------------





#---------------------------------------
# Create and set up a build controller
# for each platform build requested.
#---------------------------------------
builds = []
svn_revisions = {}

def head_svn_revision(repository_name):
    repository_URL = build_config.repository_addresses[repository_name]
    rev_command = 'svn info ' + repository_URL + ' -r HEAD | grep Revision: | cut -c11-'
    proc = sub.Popen(rev_command,
                     shell=True,
                     stdin=sub.PIPE,
                     stdout=sub.PIPE,
                     stderr=sub.STDOUT )
    revnum = proc.stdout.readline().strip()
    return int(revnum)


for spec in build_config.build_requests[build_request]:
    platform = build_config.build_specs[spec]['platform']
    print 'Setting up build ' + spec + ' on platform ' + platform
    custom_name = ''
    build = BuildController( spec, custom_name )
    for repo_name in build_config.build_specs[spec]['repositories']:
        if repo_name not in svn_revisions:
            svn_revisions[repo_name] = head_svn_revision(repo_name)
    build.svn_revisions = svn_revisions
    builds.append(build)
print 'SVN revisions:'
print svn_revisions
    
    

#---------------------------------------
# Override parameters of some or all of
# the builds here, if necessary.
#  makefile directory, svn_revision,
#  packages directory to use, etc...
#---------------------------------------
if argresults.pkg_name is not None:
    print '\nA custom packages name was provided.'
    print '  Using "' + argresults.pkg_name + '" instead of the default.\n'
    for build in builds:
        build.packages_name = argresults.pkg_name

if argresults.gmake_dir is not None:
    print '\nA custom Gmake directory was provided.'
    print '  Using "' + argresults.gmake_dir + '" instead of the default.\n'
    for build in builds:
        build.makefile_dir = argresults.gmake_dir

if argresults.util_dir is not None:
    print '\nA custom util directory was provided.'
    print ' Using "' + argresults.util_dir + '" instead of the default.\n'
    for build in builds:
        build.util_dir = argresults.util_dir


#---------------------------------------
# Initiate all builds, each in a thread
# of its own, and get the name of the
# build common to all for this script's
# use.
#---------------------------------------
build_name = builds[0].name

for bnum, build in enumerate(builds):
    for repo_name in build.svn_revisions:
        revision = build.svn_revisions[repo_name]
    build.start()  # Method inherited from Thread class;
                   # invokes 'run' method in a separate thread.


time.sleep(10)
print '\n\nBuild name is: ' + build_name
print "Waiting..."
time.sleep(15)
print '\n\nStill alive...'

#
